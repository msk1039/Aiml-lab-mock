{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64e3759",
   "metadata": {},
   "source": [
    "# Linear SVM from Scratch for Spam Detection\n",
    "We implement a linear Support Vector Machine using the primal form with hinge-loss. The optimisation goal is to minimise `||w||^2` while keeping examples on the correct side of the margin. We use stochastic sub-gradient descent: for each training point, if it lies within the margin we nudge the weight vector toward the correct label; otherwise we only apply weight decay. Although this implementation is simple, it demonstrates how SVMs emphasise the hardest-to-classify samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pd.DataFrame({\n",
    "    \"text\": [\n",
    "        \"limited time offer claim your prize now\",\n",
    "        \"meeting reminder for project update\",\n",
    "        \"win cash by entering free lottery\",\n",
    "        \"family dinner plans for saturday\",\n",
    "        \"exclusive deal just for you click\",\n",
    "        \"invoice attached for last month\",\n",
    "        \"cheap meds available order today\",\n",
    "        \"team outing scheduled at 5pm\",\n",
    "        \"congratulations you have won a voucher\",\n",
    "        \"please review the attached report\"\n",
    "    ],\n",
    "    \"label\": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
    "})\n",
    "\n",
    "train_df = records.sample(frac=0.7, random_state=1)\n",
    "test_df = records.drop(train_df.index)\n",
    "\n",
    "token_sets = [set(text.lower().split()) for text in train_df[\"text\"]]\n",
    "vocab = sorted(set().union(*token_sets))\n",
    "index_map = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "def vectorize(text):\n",
    "    \"\"\"Simple bag-of-words vector counting token frequency.\"\"\"\n",
    "    vec = np.zeros(len(vocab))\n",
    "    for token in text.lower().split():\n",
    "        if token in index_map:\n",
    "            vec[index_map[token]] += 1\n",
    "    return vec\n",
    "\n",
    "X_train = np.vstack(train_df[\"text\"].apply(vectorize).to_numpy())\n",
    "y_train = train_df[\"label\"].apply(lambda lbl: 1 if lbl == 1 else -1).to_numpy()\n",
    "\n",
    "X_test = np.vstack(test_df[\"text\"].apply(vectorize).to_numpy())\n",
    "y_test = test_df[\"label\"].apply(lambda lbl: 1 if lbl == 1 else -1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a29bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_svm(X, y, learning_rate=0.01, lambda_reg=0.01, epochs=40):\n",
    "    weights = np.zeros(X.shape[1])\n",
    "    bias = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for xi, yi in zip(X, y):\n",
    "            condition = yi * (np.dot(xi, weights) + bias)\n",
    "            if condition >= 1:\n",
    "                # Only apply L2 regularisation when the point is correctly classified\n",
    "                weights -= learning_rate * (2 * lambda_reg * weights)\n",
    "            else:\n",
    "                # Pull the decision boundary toward the misclassified sample\n",
    "                weights -= learning_rate * (2 * lambda_reg * weights - yi * xi)\n",
    "                bias += learning_rate * yi\n",
    "    return weights, bias\n",
    "\n",
    "weights, bias = train_linear_svm(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_linear_svm(X, weights, bias):\n",
    "    scores = X @ weights + bias\n",
    "    return np.where(scores >= 0, 1, -1)\n",
    "\n",
    "y_pred = predict_linear_svm(X_test, weights, bias)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix((y_test == 1).astype(int), (y_pred == 1).astype(int)))\n",
    "\n",
    "print(\"\\nDetailed report:\")\n",
    "print(classification_report((y_test == 1).astype(int), (y_pred == 1).astype(int), target_names=[\"normal\", \"spam\"]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
